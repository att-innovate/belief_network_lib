{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# belief_network_lib\n",
    "\n",
    "# Example. Using Markov blanket to reduce 20 variables to 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 Introduction\n",
    "\n",
    "We are interested in understanding the relationship between a variable X and a response variable Y. This is often done in the context of many (sometimes hundreds, thousands, or more) other variables. In general it is difficult to know if a change in Y was due to X2, and not another variable. Isolating the relationship between two variables might in general be accomplished by randomizing for the presence of the other variables. While in some circumstances this is feasible, when there are many (tens, hundreds, or thousands) of other variables, it is not feasible to acquire sufficient data to support this. If there is a way to reduce the complete set of variables, to a smaller set of variables that are most significant to Y, this would provide a smaller, more feasible set to randomize for. This smaller set of variables is precisely the Markov blanket for Y. \n",
    "\n",
    "In this example:\n",
    "- We show how belief_network_lib identifies this smaller set of variables comprising the Markov blanket.\n",
    "- We demonstrate that this significantly smaller set of variables contains the most important information to Y, by comparing a classifier of Y based upon all (20) variables, to one based on the four in the Markov blanket, and showing its (slightly) better performance. \n",
    "\n",
    "## 1.1 Example description\n",
    "\n",
    "In this example, there are twenty variables:\n",
    "\n",
    "Variables: X1, X2, X20, X21, X22, X23, X24, X3, X30, X31, X32, X33, X34, X4, X40, X41, X42, X43, X44\n",
    "\n",
    "and one response variable, Y\n",
    "\n",
    "Each of the variables is a binary variable, taking on the value 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['indices']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import network\n",
    "import network_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas import DataFrame, Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"./data_samples/bn_data_example_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>X24</th>\n",
       "      <th>X3</th>\n",
       "      <th>X30</th>\n",
       "      <th>X31</th>\n",
       "      <th>X32</th>\n",
       "      <th>X33</th>\n",
       "      <th>X34</th>\n",
       "      <th>X4</th>\n",
       "      <th>X40</th>\n",
       "      <th>X41</th>\n",
       "      <th>X42</th>\n",
       "      <th>X43</th>\n",
       "      <th>X44</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  X20  X21  X22  X23  X24  X3  X30  X31  X32  X33  X34  X4  X40  X41  \\\n",
       "0   0   0    1    0    1    1    0   0    0    0    1    1    1   0    0    0   \n",
       "1   0   0    1    1    0    0    0   0    0    0    0    1    0   0    1    0   \n",
       "2   0   1    1    0    0    1    1   0    0    1    1    1    0   0    0    0   \n",
       "3   1   0    1    0    1    1    0   0    0    0    0    1    0   1    0    1   \n",
       "4   0   0    1    0    1    1    0   0    0    0    1    1    1   0    0    1   \n",
       "\n",
       "   X42  X43  X44  Y  \n",
       "0    0    0    1  0  \n",
       "1    1    0    0  0  \n",
       "2    1    1    0  0  \n",
       "3    0    1    0  0  \n",
       "4    0    0    1  0  "
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.1 Find Markov blanket around Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_file = open(\"./data_samples/bn_data_example_3.csv\")\n",
    "aNL = network_learner.NetworkLearner(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X1', 'X2', 'X3', 'X4'}"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aNL.find_markov_blanket_for(\"Y\", significance=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.2 Build classifier based on all 20 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###2.2.1 De-bias the data by making an even split between Y=0 and Y=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices =np.where(df.Y==0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_keep = [random.choice(indices) for x in range(3508)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_rows = [df[[\"X1\", \"X2\", \"X20\", \"X21\", \"X22\", \"X23\", \"X24\", \"X3\", \"X30\", \"X31\", \"X32\", \"X33\", \"X34\", \"X4\", \"X40\", \"X41\", \"X42\", \"X43\", \"X44\"]].iloc[index] for index in to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_neg_rows = DataFrame(neg_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_feature_rows = df_neg_rows.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_indices = np.where(df.Y==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_rows = [df[[\"X1\", \"X2\", \"X20\", \"X21\", \"X22\", \"X23\", \"X24\", \"X3\", \"X30\", \"X31\", \"X32\", \"X33\", \"X34\", \"X4\", \"X40\", \"X41\", \"X42\", \"X43\", \"X44\"]].iloc[index] for index in pos_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pos_rows = DataFrame(pos_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_feature_rows = df_pos_rows.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set_df = df_neg_rows.append(df_pos_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = [0 for x in range(3508)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y.extend([1 for x in range(3508)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Randomly select two-thirds of positive\n",
    "pos_indices_train = numpy.random.choice(pos_indices, int(math.floor( (float(2)/3) *len(pos_indices))) , replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_rows_train = [df[[\"X1\", \"X2\", \"X20\", \"X21\", \"X22\", \"X23\", \"X24\", \"X3\", \"X30\", \"X31\", \"X32\", \"X33\", \"X34\", \"X4\", \"X40\", \"X41\", \"X42\", \"X43\", \"X44\"]].iloc[index] for index in pos_indices_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pos_rows_train = DataFrame(pos_rows_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_indices = to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Randomly select two-thirds of negative\n",
    "neg_indices_train = numpy.random.choice(neg_indices, int(math.floor( (float(2)/3) *len(neg_indices))), replace=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_rows_train = [df[[\"X1\", \"X2\", \"X20\", \"X21\", \"X22\", \"X23\", \"X24\", \"X3\", \"X30\", \"X31\", \"X32\", \"X33\", \"X34\", \"X4\", \"X40\", \"X41\", \"X42\", \"X43\", \"X44\"]].iloc[index] for index in neg_indices_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_neg_rows_train = DataFrame(neg_rows_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete training set\n",
    "training_set_df = df_neg_rows_train.append(df_pos_rows_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = [0 for x in range( len(neg_rows_train) )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train.extend([1 for x in range( len(pos_rows_train) )])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_indices_test = [index for index in pos_indices if index not in pos_indices_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_rows_test = [df[[\"X1\", \"X2\", \"X20\", \"X21\", \"X22\", \"X23\", \"X24\", \"X3\", \"X30\", \"X31\", \"X32\", \"X33\", \"X34\", \"X4\", \"X40\", \"X41\", \"X42\", \"X43\", \"X44\"]].iloc[index] for index in pos_indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pos_rows_test = DataFrame(pos_rows_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_indices_test = [index for index in neg_indices if index not in neg_indices_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_rows_test = [df[[\"X1\", \"X2\", \"X20\", \"X21\", \"X22\", \"X23\", \"X24\", \"X3\", \"X30\", \"X31\", \"X32\", \"X33\", \"X34\", \"X4\", \"X40\", \"X41\", \"X42\", \"X43\", \"X44\"]].iloc[index] for index in neg_indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_neg_rows_test = DataFrame(neg_rows_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete test set\n",
    "test_set_df = df_neg_rows_test.append(df_pos_rows_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test = [0 for x in range( len(neg_rows_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test.extend([1 for x in range( len(pos_rows_test))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.2.2 Build classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.fit(training_set_df.as_matrix(), Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88888888888888884"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.score(test_set_df.as_matrix(), Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.3 Classifier based on 4 Markov blanket variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vals_mb = training_set_df[[\"X1\", \"X2\", \"X3\", \"X4\"]].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 1, 1],\n",
       "       [0, 1, 0, 1],\n",
       "       [1, 1, 0, 0]])"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vals_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est2 = LogisticRegression()\n",
    "est2.fit(train_vals_mb, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90404040404040409"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est2.score(test_set_df[[\"X1\", \"X2\", \"X3\", \"X4\"]].as_matrix(), Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Attempting dimensionality reduction via PCA instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, n_components=None, whiten=False)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(training_set_df.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variances = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot variance as a function of principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes.AxesSubplot at 0x138882e90>"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiIiIiInPb/wdjivW9rdz1pAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b31d710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Series(variances).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As can be seen in the figure above, the variance captured by the principal components does not exhibit a sharp drop off, as would be the case if the variables exhibited linear relationships with each other. The number of principal components that would have to be included in any basis transformation is nearly as many as the original 20 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
